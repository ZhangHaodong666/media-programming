{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mp_ex6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ak4VuzF4SbUT"
      },
      "source": [
        "# 第6回課題：CNNで文字認識をしよう\n",
        "\n",
        "最も基本的な画像認識タスクとして、手書き文字（数字）認識をやってみましょう。   \n",
        "深層学習による画像認識のためのアーキテクチャであるCNNの実装を使います。   \n",
        "演習で配ったCIFAR-10のコードを参考にしてください。\n",
        "\n",
        "<H2><font color=\"red\">課題を提出する際は、画像が表示されている状態で保存し、このmp_ex6.ipynbファイルのみを提出してください。</font></H2>\n",
        "\n",
        "## 今回挑戦する画像認識タスク\n",
        "小規模な画像認識タスクとして、手書き文字のデータセット[MNIST(Mixed National Institute of Standards and Technology database)](http://yann.lecun.com/exdb/mnist/)を使って、０から９までの10種類の記号に対する文字認識を行います。   \n",
        "MNISTは1枚あたり28x28ピクセルで、訓練データとして60,000枚、評価データとして10,000枚の画像が与えられています。    \n",
        "\n",
        "## 利用するライブラリ\n",
        "本プログラムでは、ニューラルネットワーク実装のためのライブラリとして、Kerasを利用しています。   \n",
        "\n",
        "+ Keras Documentation: https://keras.io/ja/\n",
        "\n",
        "## 実行環境：Colaboratoryを強く推奨します\n",
        "\n",
        "CPUでも実行できると思いますが、モデルの学習に計算負荷がかかります。   \n",
        "Colaboratoryで「ランタイム＞ランタイムのタイプを変更」で「ハードウェアアクセラレータ」をGPUにしてから実行することをお勧めします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mW12ZTYXSbUU"
      },
      "source": [
        "# 1. ライブラリのインストール\n",
        "\n",
        "本プログラムでは、ニューラルネットワーク実装のためのライブラリとして、Kerasを利用しています。   \n",
        "'keras'と、そのバックエンドである'tensorflow'をインストールします。   \n",
        "\n",
        "**tensorflowのインストールによる不具合が見られるようです。**\n",
        "**Colaboratoryの使用を強くお勧めします。**\n",
        "\n",
        "## 1.1 ローカルPCの場合（非推奨）\n",
        "\n",
        "**必ず仮想環境を作ってからパッケージをインストールしてください。**   \n",
        "ガイダンスの環境設定の資料を参照して、ライブラリのインストールをお願いします。\n",
        "1. Anaconda Navigatorを開く\n",
        "2. 「Environments」のタブを開き、中央のフレームで「base(root)」とある右側の「▶」をクリックし、\"Open Terminal\"をクリック\n",
        "3. コマンドプロンプトから以下の二つのコマンドを実行  \n",
        "\n",
        "``conda install -c anaconda tensorflow``   \n",
        "``conda install -c anaconda keras``\n",
        "\n",
        "**トラブルが起きる場合はColaboratoryをご利用ください。**\n",
        "\n",
        "## 1.2 Colaboratoryの場合（推奨）\n",
        "以下のセルを実行してください。   \n",
        "**このセルはColaboratoryを起動するたびに必要となります**   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7eC_R9YASbUV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "a91bde2b-5bfa-41f6-a0b2-7c92e46cbe28"
      },
      "source": [
        "##################################\n",
        "### Colaboratoryのみ以下を実行 ###\n",
        "##################################\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    !pip install tensorflow\n",
        "    !pip install keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.30.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (47.3.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N2piFhIFSbUZ"
      },
      "source": [
        "## ライブラリを読み込み\n",
        "\n",
        "Kerasから今回使うライブラリをインポートしましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q7CfBK2WSbUa",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1db5b2e6-00ec-47fd-c57a-490b52bcb731"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# 計算するたびに違う答えにならないよう、ランダムシードを設定する\n",
        "np.random.seed(seed=0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bZTHbG6sSbUc"
      },
      "source": [
        "# 2. 学習データの準備\n",
        "\n",
        "## MNISTデータセットをダウンロード\n",
        "MNIST datasetsは様々な場面で使われているので、Kerasのライブラリの中に、データセットをダウンロードするための関数が用意されています。   \n",
        "これを使ってデータセットをダウンロードし、読み込みましょう。   \n",
        "データサイズは11MBです。    \n",
        "PCで以下のセルを実行すると、ダウンロードされたファイルがホームディレクトリの下の'.keras/datasets'の下に保存されています。   \n",
        "次回から同じPC＋アカウントでこのコマンドを実行する際は、改めてダウンロードされることはありません。   \n",
        "（Colaboratoryはランタイムを終了するとファイルがすべて消去されるため、毎回ダウンロードすることになります）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J5g7eOtFSbUd",
        "colab": {}
      },
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dgXbOe4HSbUi"
      },
      "source": [
        "入力画像を確認してみましょう。\n",
        "\n",
        "x_trainは画像の集合で、 (60,000枚) x (28 pixel) x (28 pixel)のテンソルです。\n",
        "1枚目の画像サイズを見ると、28x28であることがわかります。\n",
        "MNISTはカラー画像ではなくグレースケール画像なので、チャネルは1です（カラーの場合はRGBの3チャネルでしたね）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhGbgo8LSbUi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1e632d6c-16f5-4cff-fc1a-ee3296de5920"
      },
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dEp3X0aqSbUm"
      },
      "source": [
        "また、y_trainには60,000枚の各画像の正解のラベルが入っています。   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sj8TpZYrSbUm",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7bdea972-b564-4d8b-9cc1-4134bb62b097"
      },
      "source": [
        "print(len(y_train)) # 60,000枚の画像のラベルが入っている\n",
        "print(y_train[:10]) # 最初の10枚のラベル（整数値で記録されている）"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "[5 0 4 1 9 2 1 3 1 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HW6NyBTHSbUp"
      },
      "source": [
        "訓練画像を1枚表示させてみましょう。非常に画素が粗い画像であることがわかります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oRlLPKuiSbUq",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ba341321-a0e3-4b4d-a927-4c0c16bd61f2"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# 画像をいろいろと入れ替えてみましょう。\n",
        "id =7\n",
        "plt.imshow(x_train[id], cmap = \"gray\")\n",
        "plt.axis('off')\n",
        "\n",
        "print('Class label: ', y_train[id])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class label:  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kKRNpjF-SbUt"
      },
      "source": [
        "画像データの形を見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bC9whj_KSbUu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb85ba48-654f-41ff-e2f1-3bf2e5edf8fa"
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DyvHeSHmSbUy"
      },
      "source": [
        "CIFAR-10はカラー画像だったので、入力した時点でテンソルでしたが、グレースケール画像はチャネルが１なので、テンソルに変換する必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fevh-RPASbUz",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], x_train.shape[1], x_train.shape[2], 1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vPm8lRPZSbU1"
      },
      "source": [
        "次元が1つ増えました。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6cFPvMRjSbU2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba507be5-5f72-4c9c-f583-94812c02c7bf"
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cQwaiLyFSbU4"
      },
      "source": [
        "## 正解ラベルをone-hotベクトルに変換\n",
        "`y_train`や`y_test`は、そのアドレスに対応する画像の正解ラベルが0から9までの整数値で記録されています。   \n",
        "一方、1枚の入力画像に対してCNNが最終層で出力するのは、その画像が0から9までの各クラスである尤もらしさ（確率）ですから、それに対応するように、正解ラベルもone-hotベクトル（すなわち、正解のクラスだけが1、残りが0のベクトル）に変換しましょう。   \n",
        "\n",
        "クラスは全部で10クラスですから、10次元のone-hotベクトルに変換します。   \n",
        "たとえば正解が「６」であるような画像のクラスは\"6\"ですが、これを10次元のone-hotベクトルに変換すると、(0から数えて)6番目だけが1で残りは0であるような`[0 0 0 0 0 0 1 0 0 0]`というベクトルに変換されます。   \n",
        "これを、すべての画像（計60,000枚）について行うので、`y_train`は60,000x10の行列になります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DENwAfUZSbU4",
        "colab": {}
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cDRRXyV2SbU8"
      },
      "source": [
        "y_trainのサイズと、最初の10枚分の中身を見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bAiII4mwSbU8",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "92fa8835-f027-43d6-b870-38fc1ac70b15"
      },
      "source": [
        "print('y_train shape:', y_train.shape)\n",
        "print(y_train[:10])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train shape: (60000, 10)\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I-U0KKPgSbU_"
      },
      "source": [
        "## 画像の濃淡値を正規化\n",
        "\n",
        "各画素の濃淡値は0～255までの整数値で記録されているので、255で割って0～1までの値に正規化します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "muPR80tQSbVA",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gra1TBVHSbVE"
      },
      "source": [
        "# 3. ネットワークを設計\n",
        "\n",
        "以下のようなネットワークになるよう、モデルを設計してください。   \n",
        "コードは'ImageRecognition3.ipynb'を参考にしてください。   \n",
        "```\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
        "_________________________________________________________________\n",
        "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
        "_________________________________________________________________\n",
        "activation_2 (Activation)    (None, 24, 24, 64)        0         \n",
        "_________________________________________________________________\n",
        "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
        "_________________________________________________________________\n",
        "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
        "_________________________________________________________________\n",
        "flatten_1 (Flatten)          (None, 9216)              0         \n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 128)               1179776   \n",
        "_________________________________________________________________\n",
        "activation_3 (Activation)    (None, 128)               0         \n",
        "_________________________________________________________________\n",
        "dropout_2 (Dropout)          (None, 128)               0         \n",
        "_________________________________________________________________\n",
        "dense_2 (Dense)              (None, 10)                1290      \n",
        "_________________________________________________________________\n",
        "activation_4 (Activation)    (None, 10)                0         \n",
        "=================================================================\n",
        "Total params: 1,199,882\n",
        "Trainable params: 1,199,882\n",
        "Non-trainable params: 0\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qcDnxo0ESbVE",
        "colab": {}
      },
      "source": [
        "### 課題：教材を参考に、ネットワークのコードを書いてください\n",
        "### この行を消さないでください!!! ---mp_ex6_task1--\n",
        "\n",
        "model = Sequential()\n",
        "# Convolution 1 フィルタ32枚、各フィルタのカーネルサイズ3x3 ストライドはデフォルト (1, 1)\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "\n",
        "# 'relu'で活性化\n",
        "model.add(Activation('relu'))\n",
        "# Convolution 2 フィルタ64枚、各フィルタのカーネルサイズ3x3 ストライドはデフォルト (1, 1)\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "# 'relu'で活性化\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Max Pooling 1 (size: 2x2)\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# 25%のユニットをドロップアウト\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# テンソルを一列のベクトルに平坦化\n",
        "model.add(Flatten())\n",
        "# Full Connection 1 # ユニット数128\n",
        "model.add(Dense(128))\n",
        "# 'relu'で活性化\n",
        "model.add(Activation('relu'))\n",
        "# 50%のユニットをドロップアウト\n",
        "model.add(Dropout(0.5))\n",
        "# Full Connection 2 # ユニット数はクラス数と同じ10\n",
        "model.add(Dense(num_classes))\n",
        "# 最後の活性化関数は出力を確率にするためsoftmaxを使用\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lDOPf7lVSbVH"
      },
      "source": [
        "ネットワーク構造のサマリを出力してみましょう。   \n",
        "上で示した構造と一致しているか確認してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iMnkCY0FSbVI",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "f15b493c-5784-403e-953b-ea4f6bed9b98"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Op0uRN-uSbVM"
      },
      "source": [
        "# 4. 学習\n",
        "## 学習パラメータ設定\n",
        "\n",
        "以下のパラメータを設定してください。\n",
        "*   バッチサイズは128\n",
        "*   エポック数は12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3kh6k50aSbVM",
        "colab": {}
      },
      "source": [
        "### 課題：?を書き換えてください\n",
        "### この行を消さないでください!!! ---mp_ex6_task2--\n",
        "\n",
        "batch_size = 128 # バッチサイズ\n",
        "epochs = 12 # エポック数"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r3M3W2SDSbVP"
      },
      "source": [
        "## 最適化手法・損失関数・評価関数の設定\n",
        "最適化手法を選択します。   \n",
        "\n",
        "- 最適化手法は'Adam'を使ってください\n",
        "- 判別問題として解いてください\n",
        "- 精度は'accuracy'(正解率）で評価してください"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9G9QyqgSbVQ",
        "colab": {}
      },
      "source": [
        "### 課題：?を書き換えてください\n",
        "### この行を消さないでください!!! ---mp_ex6_task3--\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7RmPEz3XSbVT"
      },
      "source": [
        "## 学習\n",
        "\n",
        "上で設計したネットワークに訓練データを与えてモデルを学習します。   \n",
        "**時間がかかりますので覚悟してください（お手持ちのPCに不安がある方は、Google Colaboratoryをご利用ください）。**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7qyzH8ybSbVT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "d2f413f4-3de0-4709-fb92-9f3f2b1ce537"
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 14s 241us/step - loss: 0.2421 - accuracy: 0.9263 - val_loss: 0.0535 - val_accuracy: 0.9840\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0881 - accuracy: 0.9736 - val_loss: 0.0374 - val_accuracy: 0.9887\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0639 - accuracy: 0.9796 - val_loss: 0.0335 - val_accuracy: 0.9889\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0528 - accuracy: 0.9836 - val_loss: 0.0351 - val_accuracy: 0.9891\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0468 - accuracy: 0.9855 - val_loss: 0.0296 - val_accuracy: 0.9906\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 0.0337 - val_accuracy: 0.9894\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0347 - accuracy: 0.9894 - val_loss: 0.0286 - val_accuracy: 0.9923\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.0262 - val_accuracy: 0.9916\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0299 - accuracy: 0.9907 - val_loss: 0.0286 - val_accuracy: 0.9915\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.0350 - val_accuracy: 0.9903\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.0339 - val_accuracy: 0.9911\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.0317 - val_accuracy: 0.9914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fae503da828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KaG_EQv1SbVW"
      },
      "source": [
        "## 4. モデルの保存と評価\n",
        "\n",
        "モデルの学習には長い時間がかかりますので、せっかく学習したモデルは保存しておきましょう。   \n",
        "Colaboratoryで実行している場合は、保存後にPCにダウンロードしておかないと、ランタイムを停止する際に削除されてしまうのでご注意ください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vvLRQSCbSbVW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8260be3b-41b6-4926-d1eb-bfb00f34f5f8"
      },
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models') # モデルの保存先\n",
        "model_name = 'keras_mnist_trained_model' # モデルを保存する際のファイル名\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at /content/saved_models/keras_mnist_trained_model \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qU48wIjBSbVY"
      },
      "source": [
        "正解率を評価します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TFdVbJImSbVY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0286db97-0ff0-4bf4-e592-f04e46b6a162"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 134us/step\n",
            "Test loss: 0.031698465306697746\n",
            "Test accuracy: 0.9914000034332275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8cb2YspwSbVa"
      },
      "source": [
        "# 入力データに対するクラスラベルの予測\n",
        "\n",
        "\n",
        "どの画像がどのように判定されたか見てみましょう。  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VRKggoeNSbVh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "fd06da53-017c-4f2a-d8c7-c4608f50fe51"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# idをいろいろ入れ替えて、正解と予測を見比べてみましょう。\n",
        "id = 3\n",
        "plt.imshow(np.squeeze(x_test[id]), cmap='gray', vmin=0, vmax=1)\n",
        "ans = np.argmax(y_test[id])\n",
        "plt.axis('off')\n",
        "\n",
        "target = x_test[id] # 単体の入力データを用意\n",
        "predict_class = model.predict_classes( np.array([target]) )\n",
        "print(predict_class)\n",
        "print('Truth: ', ans, '\\tPredicted: ', predict_class[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "Truth:  0 \tPredicted:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uo621YPUSbVp"
      },
      "source": [
        "# 参考文献\n",
        "\n",
        "MNIST: [Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009.](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf)"
      ]
    }
  ]
}