{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFJstlz3zzzX"
   },
   "source": [
    "# 画像認識3：Convolutional Neural Network (CNN)\n",
    "深層学習による画像認識のためのアーキテクチャであるCNNの実装を動かしてみましょう。   \n",
    "\n",
    "最初のCNNアーキテクチャであるAlexNetの論文は以下で読むことができます（が、Webにわかりやすい解説が多数あります）。   \n",
    "[Krizhevsky A, Sutskever I, Hinton GE. ImageNet classification with deep convolutional neural networks. NeurIPS. 2012. DOI: 10.1145/3065386](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf)   \n",
    "今回は学習データが小規模なので、少しシンプルにしたアーキテクチャを使います。\n",
    "\n",
    "## 今回挑戦する画像認識タスク\n",
    "小規模な画像認識タスクとして、[CIFAR-10 datasets](https://www.cs.toronto.edu/~kriz/cifar.html)を使って、10クラスの物体認識を行います。   \n",
    "CIFAR-10には、'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'の10クラスの物体について、それぞれ6000枚ずつ画像が用意されています。   \n",
    "そのうち、各クラス5000枚（計50,000枚）を訓練データとし、1000枚（計10,000枚）を評価データとします。   \n",
    "各画像は32x32 pixelと非常に小さい画像なので、条件を整えても正解率は80％弱(今回のデフォルトセッティングだと60%程度）とあまり高くありませんが、その分、短時間で学習が終わるので、深層学習の勉強用によく使われます。\n",
    "\n",
    "## 利用するライブラリ\n",
    "本プログラムでは、ニューラルネットワーク実装のためのライブラリとして、Kerasを利用しています。   \n",
    "\n",
    "+ Keras Documentation: https://keras.io/ja/\n",
    "\n",
    "また、本コードは以下のサイトのものを参考にしました。   \n",
    "\n",
    "+ [Keras Documentation: Train a simple deep CNN on the CIFAR10 small images dataset.](https://keras.io/examples/cifar10_cnn/)\n",
    "\n",
    "## 実行環境：Colaboratoryを強く推奨します\n",
    "\n",
    "CPUでも実行できると思いますが、モデルの学習に計算負荷がかかります。   \n",
    "Colaboratoryで「ランタイム＞ランタイムのタイプを変更」で「ハードウェアアクセラレータ」をGPUにしてから実行することをお勧めします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uiAESp7UjYp7"
   },
   "source": [
    "# 1. ライブラリのインストール\n",
    "\n",
    "本プログラムでは、ニューラルネットワーク実装のためのライブラリとして、Kerasを利用しています。   \n",
    "'keras'と、そのバックエンドである'tensorflow'をインストールします。   \n",
    "\n",
    "**tensorflowのインストールによる不具合が見られるようです。**\n",
    "**Colaboratoryの使用を強くお勧めします。**\n",
    "\n",
    "## 1.1 ローカルPCの場合（非推奨）\n",
    "\n",
    "**必ず仮想環境を作ってからパッケージをインストールしてください。**   \n",
    "ガイダンスの環境設定の資料を参照して、ライブラリのインストールをお願いします。\n",
    "1. Anaconda Navigatorを開く\n",
    "2. 「Environments」のタブを開き、中央のフレームで「base(root)」とある右側の「▶」をクリックし、\"Open Terminal\"をクリック\n",
    "3. コマンドプロンプトから以下の二つのコマンドを実行  \n",
    "\n",
    "``conda install -c anaconda tensorflow``   \n",
    "``conda install -c anaconda keras``\n",
    "\n",
    "**トラブルが起きる場合はColaboratoryをご利用ください。**\n",
    "\n",
    "## 1.2 Colaboratoryの場合（推奨）\n",
    "以下のセルを実行してください。   \n",
    "**このセルはColaboratoryを起動するたびに必要となります**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 759
    },
    "colab_type": "code",
    "id": "NVx3IlFMjdFD",
    "outputId": "1b52a181-12c9-4276-99ab-4b03e1a065b8"
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "### Colaboratoryのみ以下を実行 ###\n",
    "##################################\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install tensorflow\n",
    "    !pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfnsha0OjYp8"
   },
   "source": [
    "## ライブラリを読み込み\n",
    "\n",
    "Kerasから今回使うライブラリをインポートしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ukc021K2jYp8",
    "outputId": "34f4e961-b3ca-4250-a95d-72c736cc650f"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 計算するたびに違う答えにならないよう、ランダムシードを設定する\n",
    "np.random.seed(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Zu8JH1LjYqE"
   },
   "source": [
    "# 2. 学習データの準備\n",
    "\n",
    "## CIFAR-10データセットをダウンロード\n",
    "CIFAR-10 datasetsは様々な場面で使われているので、Kerasのライブラリの中に、データセットをダウンロードするための関数が用意されています。   \n",
    "これを使ってデータセットをダウンロードし、読み込みましょう。   \n",
    "データサイズは163MBです。自分のPCを使う場合は、ディスクの空き容量を確認してください。  \n",
    "PCで以下のセルを実行すると、ダウンロードされたファイルがホームディレクトリの下の'.keras/datasets'の下に保存されています。   \n",
    "次回から同じPC＋アカウントでこのコマンドを実行する際は、改めてダウンロードされることはありません。   \n",
    "（Colaboratoryはランタイムを終了するとファイルがすべて消去されるため、毎回ダウンロードすることになります）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WrNNS8ZDjYqF"
   },
   "outputs": [],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lzxX9yfb8oy9"
   },
   "source": [
    "入力画像を確認してみましょう。\n",
    "\n",
    "x_trainは画像の集合で、 (50,000枚) x (32 pixel) x (32 pixel) x (RGB 3 channel)のテンソルです。\n",
    "1枚目の画像サイズを見ると、32x32x3であることがわかります。\n",
    "縦横32ピクセルの正方形の写真（とても小さい！）で、RGB3枚からなるカラー画像です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "4rlUI4lD8s17",
    "outputId": "ccc8aaea-ccbf-426d-a8d8-7227c0dd91c2"
   },
   "outputs": [],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4lHCqCr87_p"
   },
   "source": [
    "また、y_trainには50,000枚の各画像の正解のラベルが入っています。   \n",
    "このベクトルは縦ベクトル（列ベクトルともいう。横ではなく縦に値が連なるベクトル）であることに注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "F9H5hWnX88bq",
    "outputId": "f3851c6b-f6c8-443b-8232-754fe841cd0e"
   },
   "outputs": [],
   "source": [
    "print(len(y_train)) # 50,000枚の画像のラベルが入っている\n",
    "print(y_train[:10]) # 最初の10枚のラベル（整数値で記録されている）\n",
    "# ラベルの整数値とクラス名の関係を'labels'に代入\n",
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "print([labels[y_train[x][0]] for x in range(10)]) # 最初の10枚のラベル（テキストに変換したもの）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hPBD_eK9aru"
   },
   "source": [
    "訓練画像を1枚表示させてみましょう。非常に画素が粗い画像であることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "e6pXQ0gu9bEx",
    "outputId": "737242e3-4ad1-43ea-eae3-b01feffc8237"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# 画像をいろいろと入れ替えてみましょう。\n",
    "id =7\n",
    "plt.imshow(x_train[id])\n",
    "plt.axis('off')\n",
    "\n",
    "print('Class label: ', labels[y_train[id][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_siUCi7ojYqH"
   },
   "source": [
    "## 正解ラベルをone-hotベクトルに変換\n",
    "`y_train`や`y_test`は、そのアドレスに対応する画像の正解ラベルが0から9までの整数値で記録されています。   \n",
    "一方、1枚の入力画像に対してCNNが最終層で出力するのは、その画像が0から9までの各クラスである尤もらしさ（確率）ですから、それに対応するように、正解ラベルもone-hotベクトル（すなわち、正解のクラスだけが1、残りが0のベクトル）に変換しましょう。   \n",
    "\n",
    "たとえば、正解のクラスが'frog'ならば、クラスラベルは`6`となっています。クラスは全部で10クラスですから、10次元のone-hotベクトルに変換します。すると、6番目だけが1で残りは0であるような`[0 0 0 0 0 0 1 0 0 0]`というベクトルに変換されます。   \n",
    "これを、すべての画像（計50,000枚）について行うので、`y_train`は50,000x10の行列になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4l5jcHeDjYqI"
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "num_classes = 10 # 今回は10種類の物体を認識するので10クラス\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pD2pqQnW_cJx"
   },
   "source": [
    "`y_train`のサイズと、最初の10枚分の中身を見てみましょう。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "Nu6UlaS3_bj0",
    "outputId": "cd95f159-b74c-484d-9921-3448a263f5d7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('y_train shape:', y_train.shape)\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bcr6E5oEjYqK"
   },
   "source": [
    "## 画像の濃淡値を正規化\n",
    "\n",
    "各画素の濃淡値は0～255までの整数値で記録されているので、255で割って0～1までの値に正規化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G92_5facjYqM"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OtBL2LWN77a8"
   },
   "source": [
    "## Data Augmentation\n",
    "機械学習では、訓練データの数は多ければ多いほど精度が高まるのが一般的です。   \n",
    "そこで、限られた訓練データを仮想的に増やすため、データを様々に加工して新しいデータを生成する処理です。   \n",
    "どのような画像が生成されているかを見たい方は、`DataAugmentation.ipynb`を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1lAIqT8676xK"
   },
   "outputs": [],
   "source": [
    "# 与えられた画像に対し、様々な処理を加えて新しい画像を生成するためジェネレータを作成\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # 真理値．データセット全体で，入力の平均を0にします．\n",
    "        samplewise_center=False,  # 真理値．各サンプルの平均を0にします．\n",
    "        featurewise_std_normalization=False,  # 真理値．入力をデータセットの標準偏差で正規化します\n",
    "        samplewise_std_normalization=False,  # 真理値．各入力をその標準偏差で正規化します．\n",
    "        zca_whitening=False,  # 真理値．ZCA白色化を適用します．\n",
    "        zca_epsilon=1e-06,  # ZCA白色化のイプシロン．デフォルトは1e-6\n",
    "        rotation_range=20,  # 整数．画像をランダムに回転する回転範囲．\n",
    "        width_shift_range=0.2, # 浮動小数点数（横幅に対する割合）．ランダムに水平シフトする範囲．\n",
    "        height_shift_range=0.2, # 浮動小数点数（縦幅に対する割合）．ランダムに垂直シフトする範囲．\n",
    "        shear_range=0.,  # 浮動小数点数．シアー強度（反時計回りのシアー角度）．\n",
    "        zoom_range=0.,  # 浮動小数点数または[lower，upper]．ランダムにズームする範囲．浮動小数点数が与えられた場合，[lower, upper] = [1-zoom_range, 1+zoom_range]です．\n",
    "        channel_shift_range=0.,  # 浮動小数点数．ランダムにチャンネルをシフトする範囲．\n",
    "        fill_mode='nearest', # {\"constant\", \"nearest\", \"reflect\", \"wrap\"}のいずれか．デフォルトは 'nearest'です．指定されたモードに応じて，入力画像の境界周りを埋めます．\n",
    "        cval=0.,  # 浮動小数点数または整数．fill_mode = \"constant\"のときに境界周辺で利用される値．\n",
    "        horizontal_flip=True,  # 真理値．水平方向に入力をランダムに反転します．\n",
    "        vertical_flip=False,  # 真理値．垂直方向に入力をランダムに反転します．\n",
    "        rescale=None, # 画素値のリスケーリング係数．デフォルトはNone．Noneか0ならば，適用しない．それ以外であれば，(他の変換を行う前に) 与えられた値をデータに積算する．\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None, # 各入力に適用される関数です．この関数は他の変更が行われる前に実行されます．この関数は3次元のNumpyテンソルを引数にとり，同じshapeのテンソルを出力するように定義する必要があります．\n",
    "        data_format=None, # {\"channels_first\", \"channels_last\"}のどちらか．\"channels_last\"の場合，入力のshapeは(samples, height, width, channels)となり，\"channels_first\"の場合は(samples, channels, height, width)となります．デフォルトはKerasの設定ファイル~/.keras/keras.jsonのimage_data_formatの値です．一度も値を変更していなければ，\"channels_last\"になります．\n",
    "        validation_split=0.0) # 浮動小数点数．検証のために予約しておく画像の割合（厳密には0から1の間）です．\n",
    "#datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7IqkOfBCjYqO"
   },
   "source": [
    "# 3. ネットワークを設計\n",
    "\n",
    "上から順に画像データが通過していくと考えてください。   \n",
    "なお、Dropoutとは、モデルが訓練データに過学習しないよう、ユニットのうちいくつかをランダムに無視するものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpjou84MjYqP"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Convolution 1 フィルタ32枚、各フィルタのカーネルサイズ3x3 ストライドはデフォルト (1, 1)\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "# 'relu'で活性化\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Convolution 2 フィルタ32枚、各フィルタのカーネルサイズ3x3 ストライドはデフォルト (1, 1)\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "# 'relu'で活性化\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Max Pooling 1 (size: 2x2)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 25%のユニットをドロップアウト\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Convolution 3 フィルタ64枚、各フィルタのカーネルサイズ3x3 ストライドはデフォルト (1, 1)\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "# 'relu'で活性化\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Convolution フィルタ64枚、各フィルタのカーネルサイズ3x3 ストライドはデフォルト (1, 1)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "# 'relu'で活性化\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Max Pooling-2 (size: 2x2)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 25%のユニットをドロップアウト\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# テンソルを一列のベクトルに平坦化\n",
    "model.add(Flatten())\n",
    "\n",
    "# Full Connection 1 # ユニット数512\n",
    "model.add(Dense(512))\n",
    "# 'relu'で活性化\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 50%のユニットをドロップアウト\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Full Connection 2 # ユニット数はクラス数と同じ10\n",
    "model.add(Dense(num_classes))\n",
    "# 最後の活性化関数は出力を確率にするためsoftmaxを使用\n",
    "model.add(Activation('softmax')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ALlMxpMTdOqc"
   },
   "source": [
    "ネットワーク構造のサマリを出力してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "colab_type": "code",
    "id": "Vh31vWBtqr9b",
    "outputId": "43ec6c30-d645-4e81-a4ef-550943c42e39"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u4JU3VENjYqB"
   },
   "source": [
    "# 4. 学習\n",
    "## 最適化手法・損失関数・評価関数の設定\n",
    "最適化手法を選択します。   \n",
    "ここではよく使われる'Adam'と'RMSprop'のコードを書いておきます。   \n",
    "損失関数は、今回は判別問題（Classification）なので`'categorical_crossentropy'`を指定します。   \n",
    "もし回帰問題（Regression) ならば、`'mean_squared_error'`や`'mean_absolute_error'`を指定します。   \n",
    "取り得る選択肢は[Kerasドキュメント](https://keras.io/ja/losses/)を参照してください。   \n",
    "評価関数は`'accuracy'`としておきます。これは`'categorical_accuracy'`がデフォルト値です。詳しくは[Kerasドキュメント](https://keras.io/ja/metrics/)か[ソース](https://github.com/keras-team/keras/blob/c2e36f369b411ad1d0a40ac096fe35f73b9dffd3/keras/metrics.py)を参照してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7hYk7ZpJjYqS"
   },
   "outputs": [],
   "source": [
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              # RMSprop optimizer\n",
    "              optimizer= keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),\n",
    "              # Adam optimizer\n",
    "              # optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "svT3xoGFxcDo"
   },
   "source": [
    "## 学習パラメータ設定\n",
    "\n",
    "以下のパラメータを設定\n",
    "*   バッチサイズ：誤差を逆伝搬する際に、サンプルひとつずつ行うのではなく、いくつかのサンプルの誤差をまとめて逆伝搬します。そのときの1まとまりのサンプル数がバッチサイズです。1, 32, 128, 256, 512などが使われます。バッチサイズが大きいほど、特異値の影響を受けにくくなります。\n",
    "*   エポック数：深層学習では同じ訓練データを何度も使ってパラメタを更新します。ここで指定するのは最大繰り返し回数です\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sSSYw1ewjYqB"
   },
   "outputs": [],
   "source": [
    "batch_size = 32 # バッチサイズ\n",
    "epochs = 10 # エポック数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pvApAvB8Dvei"
   },
   "source": [
    "## 学習\n",
    "\n",
    "上で設計したネットワークに訓練データを与えてモデルを学習します。   \n",
    "**時間がかかりますので覚悟してください（お手持ちのPCに不安がある方は、Google Colaboratoryをご利用ください）。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "G6miyrdbjYqV",
    "outputId": "3197137b-f550-4f72-f1a7-4cc8fb6b7794"
   },
   "outputs": [],
   "source": [
    "data_augmentation = True # Data Augmentationを行わない場合の精度を見たい方は、ここをFalseにしてください\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gu-gsmjcjYqX"
   },
   "source": [
    "# 5. モデルの保存と評価\n",
    "\n",
    "モデルの学習には長い時間がかかりますので、せっかく学習したモデルは保存しておきましょう。   \n",
    "Colaboratoryで実行している場合は、保存後にPCにダウンロードしておかないと、ランタイムを停止する際に削除されてしまうのでご注意ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Kmyu8Ft9jYqX",
    "outputId": "75fea94a-64c6-4d8e-e856-0edbeeeb76a5"
   },
   "outputs": [],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'saved_models') # モデルの保存先\n",
    "model_name = 'keras_cifar10_trained_model' # モデルを保存する際のファイル名\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UGVL8Z92FPzE"
   },
   "source": [
    "評価用データにより正解率を評価します。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "XT05QoQ6FUmE",
    "outputId": "af7622bf-b058-4e90-9e83-6bbf875abdf7"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3fyWn52FPnZ"
   },
   "source": [
    "# 6. 入力データに対するクラスラベルの予測\n",
    "\n",
    "## 複数の評価データを一気に評価する\n",
    "\n",
    "学習したモデルを使って、画像のクラスを予測してみましょう。   \n",
    "\n",
    "評価データ`x_test`の最初の100枚に対して、クラスラベルを予測します。   \n",
    "その後、正解ラベルとの混同行列を出力してみましょう。   \n",
    "私の手元の結果では、`cat`を`dog`に誤りがちでしたが、皆さんはどうでしたか？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "hrFDoZxHjYqc",
    "outputId": "e0b16804-87fc-4743-9a24-74743c25fc5b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predict_classes = model.predict_classes(x_test[:100,], batch_size=32, verbose=0)\n",
    "true_classes = np.argmax(y_test[:100],1)\n",
    "print('Confusion matrix:\\n', confusion_matrix(true_classes, predict_classes))\n",
    "print('Predicted labels:', predict_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9z59yn2IHojv"
   },
   "source": [
    "## 1枚の画像に対する認識結果を確認する\n",
    "\n",
    "順番に、どの画像がどのように判定されたか見てみましょう。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "zVnmq2jumEmC",
    "outputId": "e1ac869b-a085-47b3-b28e-c58a25d3d7f3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# idをいろいろ入れ替えて、正解と予測を見比べてみましょう。\n",
    "id = 100\n",
    "plt.imshow(x_test[id])\n",
    "ans = np.argmax(y_test[id])\n",
    "plt.axis('off')\n",
    "\n",
    "target = x_test[id] # 単体の入力データを用意\n",
    "predict_class = model.predict_classes( np.array([target]) )\n",
    "print(predict_class)\n",
    "print('Truth: ', labels[ans], '\\tPredicted: ', labels[predict_class[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kr_R-vAuV93A"
   },
   "source": [
    "# 発展的演習\n",
    "## Datasets\n",
    "100クラスの一般物体認識タスクとして、[CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html)があります。  \n",
    "変更点はわずかなのでぜひ試してみてください。   \n",
    "\n",
    "## ネットワーク構造\n",
    "モデルの構造を変えたらどうなるか試してみましょう。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UvOl3ePmXDve"
   },
   "source": [
    "# 参考文献\n",
    "CIFAR-10/CIFAR-100: [Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009.](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
