{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像認識2：はじめてのNeural Network\n",
    "\n",
    "深層学習に進む前に、ニューラルネットワークで簡単な分類問題を解いてみましょう。\n",
    "\n",
    "## 今回挑戦する画像認識タスク\n",
    "\n",
    "機械学習で最も有名だと言っても過言ではない、アヤメのデータセットを使って分類問題を解いてみましょう。   \n",
    "これは3種類のアヤメ（'setosa'、'versicolor'、'virginica'）それぞれ50個ずつの個体について、ガクの長さ（sepal length)、ガクの幅（sepal width)、花弁の長さ(petal length)、花弁の幅(petal width)を調べたもので、計150個のサンプルからなり、1つのサンプルには4つの値を持っています。   \n",
    "その4つの値（ガク・花弁の長さ・幅）から、そのサンプルがどの種類に属するかを分類するという課題です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ライブラリのインストール\n",
    "\n",
    "本プログラムでは、ニューラルネットワーク実装のためのライブラリとして、Kerasを利用しています。   \n",
    "'keras'と、そのバックエンドである'tensorflow'をインストールします。   \n",
    "\n",
    "**tensorflowのインストールによる不具合が見られるようです。**\n",
    "**Colaboratoryの使用を強くお勧めします。**\n",
    "\n",
    "## 1.1 ローカルPCの場合（非推奨）\n",
    "\n",
    "**必ず仮想環境を作ってからパッケージをインストールしてください。**   \n",
    "ガイダンスの環境設定の資料を参照して、ライブラリのインストールをお願いします。\n",
    "1. Anaconda Navigatorを開く\n",
    "2. 「Environments」のタブを開き、中央のフレームで「base(root)」とある右側の「▶」をクリックし、\"Open Terminal\"をクリック\n",
    "3. コマンドプロンプトから以下の二つのコマンドを実行  \n",
    "\n",
    "``conda install -c anaconda tensorflow``   \n",
    "``conda install -c anaconda keras``\n",
    "\n",
    "**トラブルが起きる場合はColaboratoryをご利用ください。**\n",
    "\n",
    "## 1.2 Colaboratoryの場合（推奨）\n",
    "以下のセルを実行してください。   \n",
    "**このセルはColaboratoryを起動するたびに必要となります**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "### Colaboratoryのみ以下を実行 ###\n",
    "##################################\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install tensorflow\n",
    "    !pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリを読み込み\n",
    "\n",
    "Kerasから今回使うライブラリをインポートしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# 計算するたびに違う答えにならないよう、ランダムシードを設定する\n",
    "np.random.seed(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 学習データの準備\n",
    "\n",
    "## アヤメのデータセットを読み込み\n",
    "アヤメのデータセットは様々な場面で使われているので、scikit-learnのライブラリの中にあらかじめ含まれています。   \n",
    "以下のコードで読み込んでください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X= iris.data # 各サンプルについて、ガク・花弁の長さ・幅に関する4つのデータ\n",
    "Y = iris.target # 各サンプルについて、アヤメの種類に相当するクラス番号\n",
    "labels = iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yには、それぞれのサンプルにおけるアヤメの種類に対応するクラス番号が記録されています。   \n",
    "これは、0のとき'setosa'、1のとき'versicolor'、2のとき'virginica'です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('最初の10サンプル：', Y[:10])\n",
    "print('ラベルの種類：',labels)\n",
    "print('最初の10サンプルのラベル：', [labels[l] for l in Y[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xには、それぞれのサンプルにおけるガクの長さ（sepal length)、ガクの幅（sepal width)、花弁の長さ(petal length)、花弁の幅(petal width)の4つの値が記録されています。   \n",
    "Xの最初の3個のサンプルを書き出してみましょう。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Xのサイズ：', X.shape)\n",
    "for i in range(3):\n",
    "    print(i,'個目のサンプル：', X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正解ラベルをone-hotベクトルに変換\n",
    "以上でわかるように、`y`は、3種類のアヤメの種類（'setosa'、'versicolor'、'virginica'）に対応する正解ラベルが0, 1, 2のいずれかの整数値で記録されています。   \n",
    "これを判別するニューラルネットワークを作りたいのですが、そのネットワークの最終層の出力はどのようなものであればいいでしょうか？   \n",
    "\n",
    "入力したサンプルのデータ（ガクの幅・長さ、花弁の幅・長さ）に対して出力するのは、そのサンプルが0, 1, 2のそれぞれのクラスである尤もらしさ（確率）です。   \n",
    "たとえば、正しいクラスが\"1\"である場合、期待される出力は`[0.1 0.8 0.1]`のように（0から数えて）1番目の次元の確率が最も高いベクトル、   \n",
    "正しいクラスが\"2\"である場合、期待される出力は`[0 0.1 0.9]`のように、2番目の次元の確率が最も高いベクトルということになります。   \n",
    "\n",
    "そこで、それに対応するように、正解ラベルもone-hotベクトル（すなわち、正解のクラスだけが1、残りが0のベクトル）に変換しましょう。   \n",
    "\n",
    "クラスは全部で3クラスですから、3次元のone-hotベクトルに変換します。   \n",
    "たとえば正解が「1」であるようなサンプルのクラスは\"1\"ですが、これを1次元のone-hotベクトルに変換すると、(0から数えて）1番目だけが1で残りは0であるような`[0 1 0]`というベクトルに変換されます。   \n",
    "これを、すべてのサンプル（計150個）について行うので、`y`は150x3の行列になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = keras.utils.to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yのサイズと、最初の10サンプル分の中身を見てみましょう。   \n",
    "なお、最初の10サンプルのクラス（アヤメの種類）はすべて\"0\"です。   \n",
    "（このデータセットは、最初の50サンプルが'setosa'（クラスラベルは\"0\")、   \n",
    "次の50サンプルが'versicolor'（クラスラベルは\"1\"）、最後の50サンプルが'virginica'（クラスラベルは\"2\"）となっています）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('yのサイズ:', y.shape)\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練データと評価データに分けましょう。   \n",
    "分ける比率は8:2とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ネットワークを設計\n",
    "\n",
    "今回は、4次元の入力データに対し、次のような構造のネットワークを作りたいと思います（インターネットに接続する環境で見てください）。   \n",
    "<img src='http://www.hal.t.u-tokyo.ac.jp/~yamakata/lecture/mediaproc/mediaproc6/ImageRecognition2.png'></img>   \n",
    "1層目は入力が4次元、ユニット数３の全結合層（Full connection layer)、活性化関数は'relu'です。   \n",
    "2層目は入力が3次元、ユニット数が3の全結合層で、その出力を最後に'softmax'関数により確率に変換して出力します。   \n",
    "\n",
    "これを実装すると以下のようになります。   \n",
    "なお、上図では左から入力して層を通過していますが、下のコードでは上から順にサンプルが通過していくと考えてください。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Full Connection 1 # 入力は4次元、ユニット数は100\n",
    "model.add(Dense(input_dim=4, units=100))\n",
    "\n",
    "# 'relu'で活性化\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Full Connection 2 # 入力は100次元、ユニット数は3\n",
    "# これが最終層なので、ユニット数はクラス数（=3）と同じである必要がある\n",
    "model.add(Dense(input_dim=100, units=3))\n",
    "\n",
    "# 最後の活性化関数は出力を確率にするためsoftmaxを使用\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ネットワーク構造のサマリを出力してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 学習\n",
    "## 最適化手法・損失関数・評価関数の設定\n",
    "最適化手法を選択します。   \n",
    "ここではよく使われる'Adam'を使います。   \n",
    "損失関数は、今回は判別問題（Classification）なので`'categorical_crossentropy'`を指定します。   \n",
    "もし回帰問題（Regression) ならば、`'mean_squared_error'`や`'mean_absolute_error'`を指定します。   \n",
    "取り得る選択肢は[Kerasドキュメント](https://keras.io/ja/losses/)を参照してください。   \n",
    "評価関数は`'accuracy'`としておきます。これは`'categorical_accuracy'`がデフォルト値です。詳しくは[Kerasドキュメント](https://keras.io/ja/metrics/)か[ソース](https://github.com/keras-team/keras/blob/c2e36f369b411ad1d0a40ac096fe35f73b9dffd3/keras/metrics.py)を参照してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習パラメータ設定\n",
    "\n",
    "以下のパラメータを設定\n",
    "*   バッチサイズ：誤差を逆伝搬する際に、サンプルひとつずつ行うのではなく、いくつかのサンプルの誤差をまとめて逆伝搬します。そのときの1まとまりのサンプル数がバッチサイズです。1, 32, 128, 256, 512などが使われます。バッチサイズが大きいほど、特異値の影響を受けにくくなります。\n",
    "*   エポック数：深層学習では同じ訓練データを何度も使ってパラメタを更新します。ここで指定するのは最大繰り返し回数です\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # バッチサイズ\n",
    "epochs = 50 # エポック数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "\n",
    "上で設計したネットワークに訓練データを与えてモデルを学習します。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 評価\n",
    "## Closed test\n",
    "学習に使ったサンプルについて、予測精度を計算します。   \n",
    "このような評価をClosed testと呼びます。   \n",
    "モデルはこのサンプルを見たことがあるわけなので、精度は高くなるのが一般的です。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=1)\n",
    "print('Closed test loss:', score[0])\n",
    "print('Closed test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open test\n",
    "次に、学習に使ったサンプルとは別の、評価用について、予測精度を計算します。   \n",
    "このような評価をOpen testと呼びます。   \n",
    "これはモデルが見たことのないサンプルなので、これが実用上の精度評価となります。   \n",
    "Closed testの精度が十分高いのに、Open testの精度が低い場合は、訓練データに対しモデルが過学習を起こしていると考えることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Open test loss:', score[0])\n",
    "print('Open test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 入力データに対するクラスラベルの予測\n",
    "\n",
    "## 複数の評価データを一気に評価する\n",
    "\n",
    "学習したモデルを使って、個々のサンプルのクラスを予測してみましょう。   \n",
    "その後、正解ラベルとの混同行列を出力してみましょう。    \n",
    "'versicolor'と'virginica'を時々間違えるようです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predict_classes = model.predict_classes( X )\n",
    "print('Confusion matrix:\\n', confusion_matrix(Y, predict_classes))\n",
    "print('Prediction labels:\\n', predict_classes)\n",
    "print('Ground truth:\\n', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## あるサンプルの予測確率を計算する\n",
    "あるサンプルが'setosa'、'versicolor'、'virginica'のそれぞれのクラスに属する予測確率を出力してみましょう。   \n",
    "predが予測、GTが正解（Ground Truth）です。ニューラルネットワークは、この二つのベクトルが一致するように学習を行っています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict( X )\n",
    "\n",
    "# 予測対象とするサンプルのID.ここをいろいろと変えて試してみましょう。\n",
    "# ID=0～49のとき'setosa'、ID=50～99のとき'versicolor'、ID=100～149のとき'virginica'です\n",
    "id = 72 \n",
    "\n",
    "print(id, '個目のサンプルに対する３つの種類の確率')\n",
    "print('\\tsetosa\\tversicolor\\tvirginica')\n",
    "print('pred\\t{:>.4f}\\t{:>.4f}\\t{:.4f}'.\n",
    "      format(predictions[id][0],predictions[id][1],predictions[id][2]))\n",
    "print('TG\\t{:>.4}\\t{:>.4}\\t{:>.4}'.\n",
    "      format(y[id][0],y[id][1],y[id][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 発展的課題\n",
    "モデルのユニットや構造、学習パラメータを変えて、結果がどのように変わるか試しましょう。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
