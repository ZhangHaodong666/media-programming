{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colaboratoryで実行する場合\n",
    "以下を実行して、外部ファイルをダウンロードしてください。   \n",
    "**このセルはColaboratoryを起動するたびに必要となります**   \n",
    "**「ランタイム＞ランタイムのタイプを変更」で「ハードウェアアクセラレータ」をGPUにしてから実行することをお勧めします。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "### Colaboratoryのみ以下を実行 ###\n",
    "##################################\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !wget -P ./img http://www.hal.t.u-tokyo.ac.jp/~yamakata/lecture/mediaproc/mediaproc6/mediaproc6-MobileNetSSD.zip\n",
    "    !unzip img/mediaproc6-MobileNetSSD.zip -d img/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-Shot multi-box Detector (SSD) を試してみよう！\n",
    "\n",
    "\n",
    "Single-Shot multi-box Detector(SSD)とは、Deep Learningによる画像の領域検出アルゴリズムの一種です。   \n",
    "ここではGoogleにより高速化されたアルゴリズムであるMobileNetを使って、SSDを体験してみましょう。\n",
    "\n",
    "- SSDの論文：Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg, \"SSD: Single Shot MultiBox Detector\", ECCV2016. view on https://link.springer.com/chapter/10.1007/978-3-319-46448-0_2 or https://arxiv.org/abs/1512.02325\n",
    "- Mobile Netの論文：Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam. (17 Apr 2017). “MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”. Computer Vision and Pattern Recognition. view on https://arxiv.org/abs/1704.04861\n",
    "\n",
    "Deep Learningによる画像認識にはいろいろなプラットフォームと実装がありますが、\n",
    "ここではopencv3.3以上に組み込まれたDeep LearningのライブラリCaffeを使いたいと思います。   \n",
    "物体検出プログラムを実行するには、学習済みのモデルとプロトテキストが必要です。\n",
    "\n",
    "- prototxt: ニューラルネットの構造を記述するためのCaffe独自のテキスト形式\n",
    "- caffeemodel: Caffe形式の学習済みモデル\n",
    "\n",
    "今回使用するモデルは、Microsoftが提供している画像のデータセット[MS-COCO](http://cocodataset.org/#home)で学習したのち、[Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/)というデータセットでfine-tuneしたモデルです。   \n",
    "Pascal VOCは、背景（background)に加え、以下の20種類の物体について、その領域（bouding-box)とラベルが指定されたデータセットです。   \n",
    "\n",
    "```\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"```\n",
    "            \n",
    "ですので、これらの20種類のみ物体の領域検出が可能ということになります。\n",
    "\n",
    "モデルやプロトテキストは以下に置かれたものをダウンロードして使用します。   \n",
    "[https://github.com/chuanqi305/MobileNet-SSD](https://github.com/chuanqi305/MobileNet-SSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. モデルのダウンロード\n",
    "\n",
    "学習済みのモデルをダウンロードします。   \n",
    "以下を**1回のみ**実行してください。  \n",
    "ダウンロードされたモデルは、このnotebookが置かれているフォルダ内にある、MobileNet-SSDという名前のフォルダの下に入ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MobileNet-SSD/LICENSE', <http.client.HTTPMessage at 0x1a26033b808>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# この作業は1回のみで結構です！1回だけ、以下のコードの最初と最後にある「'''」を消してから実行してください。\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "if not os.path.exists('MobileNet-SSD'):\n",
    "    os.mkdir('MobileNet-SSD')\n",
    "\n",
    "# モデルのダウンロード元\n",
    "caffemodel_link = 'https://github.com/chuanqi305/MobileNet-SSD/raw/master/mobilenet_iter_73000.caffemodel'\n",
    "prototxt_link = 'https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/master/deploy.prototxt'\n",
    "license_link = 'https://github.com/chuanqi305/MobileNet-SSD/blob/master/LICENSE'\n",
    "\n",
    "# モデルのダウンロード先\n",
    "caffemodel_save = 'MobileNet-SSD/mobilenet_iter_73000.caffemodel'\n",
    "prototxt_save = 'MobileNet-SSD/deploy.prototxt'\n",
    "license_save = 'MobileNet-SSD/LICENSE'\n",
    "\n",
    "# ダウンロードの実行\n",
    "urllib.request.urlretrieve(caffemodel_link, caffemodel_save)\n",
    "urllib.request.urlretrieve(prototxt_link, prototxt_save)\n",
    "urllib.request.urlretrieve(license_link, license_save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 実行プログラム\n",
    "\n",
    "引数として与えられたprototxtとmodelを使い、入力画像imageについて物体検出する関数`DNN_ObjectDetection`を以下のように定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def DNN_ObjectDetection(image, prototxt, model, confidence):\n",
    "    inWidth = 300\n",
    "    inHeight = 300\n",
    "    inScaleFactor = 0.007843\n",
    "    meanVal = 127.5\n",
    "    \n",
    "    # Pascal VOCで検出対象となっている２０クラスと背景(background)\n",
    "    labels = ['background', \n",
    "              'aeroplane', 'bicycle', 'bird', 'boat','bottle', 'bus', 'car', 'cat', 'chair', 'cow', \n",
    "              'dining table','dog', 'horse', 'motorbike', 'person', 'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']\n",
    "    label_colors = np.random.uniform(0, 255, size=(len(labels), 3)) # それぞれのラベルに適当な色を割り当てる\n",
    "\n",
    "    # 画像の読み込み\n",
    "    image = cv2.imread(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    (h, w) = image.shape[:2] # 画像サイズの取得\n",
    "\n",
    "    # ネットワークの準備\n",
    "    dnn = cv2.dnn.readNetFromCaffe(prototxt, model)\n",
    "\n",
    "    # 画像を300x300にリサイズし、正規化してblob形式に変換\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (inWidth, inHeight)), inScaleFactor, (inWidth, inHeight), meanVal)\n",
    "    dnn.setInput(blob)\n",
    "    \n",
    "    # 領域の検出\n",
    "    detections = dnn.forward()\n",
    "\n",
    "    # 検出された各領域について、画像上に矩形とラベルを描画\n",
    "    for i in np.arange(0, detections.shape[2]):\n",
    "        # confidenceがあらかじめ定めた値よりも大きい場合のみ\n",
    "        if detections[0, 0, i, 2] > confidence:\n",
    "            idx = int(detections[0, 0, i, 1]) # 検出された領域のクラス番号\n",
    "            print('クラス名：{}\\t 信頼度：{:.2f}%'.format(labels[idx], detections[0, 0, i, 2] * 100))\n",
    "\n",
    "            # 検出された領域の対角２点の座標を獲得\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h]) \n",
    "            (bbox_X1, bbox_Y1, bbox_X2, bbox_Y2) = box.astype('int')\n",
    "            # 検出された領域の輪郭線を描画\n",
    "            cv2.rectangle(image, (bbox_X1, bbox_Y1), (bbox_X2, bbox_Y2), label_colors[idx], 2)\n",
    "            # 検出された領域のラベルを描画\n",
    "            y = bbox_Y1 - 15 if bbox_Y1 - 15 > 15 else bbox_Y1 + 15 # ラベルの描画位置\n",
    "            cv2.putText(image, labels[idx], (bbox_X1, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, label_colors[idx], 2)\n",
    "\n",
    "    # 画像の描画\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image)\n",
    "    cv2.imwrite('img/MobileNet-SDD.jpg', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 画像の領域検出の実行\n",
    "\n",
    "入力画像をいろいろと変えて結果の変わり方を見てみましょう。   \n",
    "また、信頼度も変えてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検出した領域の信頼度に対する閾値（この値以上の信頼度の領域はOKとする）\n",
    "confidence = 0.2\n",
    "\n",
    "#image = 'img/adorable-animal-blur-850602.jpg' # https://www.pexels.comより取得\n",
    "#image = 'img/animals-cats-cute-45170.jpg' # https://www.pexels.comより取得\n",
    "#image = 'img/aeroplanes-aircraft-airline-163792.jpg' # https://www.pexels.comより取得\n",
    "#image = 'img/bangkok-buildings-cars-708764.jpg' # https://www.pexels.comより取得\n",
    "image = \"img/1024px-Super_Tuesday_(6814264898).jpg\" # https://upload.wikimedia.org/wikipedia/commons/thumb/a/a4/Super_Tuesday_%286814264898%29.jpg/1024px-Super_Tuesday_%286814264898%29.jpg より取得\n",
    "\n",
    "prototxt=\"MobileNet-SSD/deploy.prototxt\"\n",
    "model=\"MobileNet-SSD/mobilenet_iter_73000.caffemodel\"\n",
    "\n",
    "DNN_ObjectDetection(image, prototxt, model, confidence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
